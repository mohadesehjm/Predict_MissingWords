{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0In83a5qjok"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oQy495rqs2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97038ac-0e71-4088-8aab-efb218ff4d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.nn import functional as F\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSXp3wgMm1Yb",
        "outputId": "bd8089e9-d2d7-4eda-8f19-014ad68e5181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/df_15000.csv')\n",
        "\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df['QUESTION'].values\n",
        "sentences1 = df['QUESTION'].values\n",
        "labels = df['ANSWER'].values\n",
        "\n",
        "combine = ''\n",
        "combine1 = ''\n",
        "\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "    # print('Encoding the tokens..',cnt)\n",
        "    sent = sentences[i].replace('[BLANK]',labels[i],1)\n",
        "    combine1 = combine1+\"\\n\\n\"+sent\n",
        "\n",
        "    sent1 = sentences[i].replace('[BLANK]','BLANK',1)\n",
        "    combine = combine+\"\\n\\n\"+sent1"
      ],
      "metadata": {
        "id": "mJNAl9-Thctr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/Tdf_5000.csv')"
      ],
      "metadata": {
        "id": "_V7t_G9_r0d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "6CyXGCsMhzyx",
        "outputId": "a7cef205-5b1e-4877-86b4-230e29c08b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nIncreased content consumption on mobile devices may further drive distributors such as cable and telecom operators to release over-the-top mobile video offerings, while shifting ad budgets to the Internet. Smartphone and tablet BLANK reached 33% of total online video plays in the fourth quarter, according to Ooyala, doubling from 17% in 4Q13. A number of content distributors have responded to this trend, with Verizon announcing a mobile video service to debut this summer.\\n\\nNational Australia Bank's earnings prospects will rely on an ongoing strength of business and corporate banking, which jointly contributed 65% of its 1H pretax profit. These units showed stable net interest margins, BLANK a weakness in consumer banking. Market income also supports its revenue, as market volatility fuels demand for risk management and treasury business. Reduced credit costs bode well for its earnings too. Separately, NAB and peers' profit will suffer from the proposed 6-bp levy on liabilities.\\n\\nThe \""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rbuBM1Ds1zj"
      },
      "outputs": [],
      "source": [
        "inputs1 = tokenizer(combine1, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeLNCzlZs14x",
        "outputId": "5de9291d-f64e-4f8e-afc1-d2baec1cbe60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "inputs1.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(combine, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n"
      ],
      "metadata": {
        "id": "-sHIBD77Cgxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.keys()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH5smBaACg45",
        "outputId": "aceea25d-ed32-4b98-e6e4-6fcef90f33e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Psa37OFs1_x",
        "outputId": "df431b7d-1f1e-489a-dcc4-b352e738b693"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  3445,  4180,  8381,  2006,  4684,  5733,  2089,  2582,  3298,\n",
              "         22495,  2107,  2004,  5830,  1998, 18126,  9224,  2000,  2713,  2058,\n",
              "          1011,  1996,  1011,  2327,  4684,  2678, 14927,  1010,  2096,  9564,\n",
              "          4748, 26178,  2000,  1996,  4274,  1012, 26381,  1998, 13855,  8744,\n",
              "          2584,  3943,  1003,  1997,  2561,  3784,  2678,  3248,  1999,  1996,\n",
              "          2959,  4284,  1010,  2429,  2000,  1051, 18232,  2721,  1010, 19383,\n",
              "          2013,  2459,  1003,  1999,  1018,  4160, 17134,  1012,  1037,  2193,\n",
              "          1997,  4180, 22495,  2031,  5838,  2000,  2023,  9874,  1010,  2007,\n",
              "          2310, 21885,  2239, 13856,  1037,  4684,  2678,  2326,  2000,  2834,\n",
              "          2023,  2621,  1012,  2120,  2660,  2924,  1005,  1055, 16565, 16746,\n",
              "          2097, 11160,  2006,  2019,  7552,  3997,  1997,  2449,  1998,  5971,\n",
              "          8169,  1010,  2029, 10776,  5201,  3515,  1003,  1997,  2049,  1015,\n",
              "          2232,  3653,  2696,  2595,  5618,  1012,  2122,  3197,  3662,  6540,\n",
              "          5658,  3037, 17034,  1010,  8744,  1037, 11251,  1999,  7325,  8169,\n",
              "          1012,  3006,  3318,  2036,  6753,  2049,  6599,  1010,  2004,  3006,\n",
              "          5285, 10450, 18605, 20145,  5157,  2005,  3891,  2968,  1998,  9837,\n",
              "          2449,  1012,  4359,  4923,  5366,  8945,  3207,  2092,  2005,  2049,\n",
              "         16565,  2205,  1012, 10329,  1010,  6583,  2497,  1998, 12746,  1005,\n",
              "          5618,  2097,  9015,  2013,  1996,  3818,  1020,  1011, 17531, 12767,\n",
              "          2006, 22393, 14680,  1012,  1996,  3112,  1997,  9099, 28621,  2850,\n",
              "          1005,  1055,  1002,  2321,  4551,  4366,  2104,  1996,  2167,  2137,\n",
              "          2489,  3119,  3820, 25484,  2006,  1996,  2194,  4760,  1996, 13117,\n",
              "          1005,  1055, 14920,  2011,  1996,  1057,  1012,  1055,  1012,  4504,\n",
              "          2013, 10662,  1011,  2241,  9147,  1012,  1037,  2093,  1011,  2266,\n",
              "          6583,  6199,  2050,  5997,  2089,  2196,  2131,  1037,  3382,  2000,\n",
              "         10663,  2054,  2052,  2022,  1037,  2086,  1011,  2146, 18010,  2832,\n",
              "          1010,  3391,  2065,  1037,  3951,  4150,  2343,  1998,  8744,  1996,\n",
              "         14920,  1012,  2087,  6583,  6199,  2050, 11936,  7392,  2005,  2019,\n",
              "          2779,  1016, 16653,  2006,  1996,  7922,  1012,  3032,  2663,  2087,\n",
              "          1997,  1996,  3588,  8931,  2008,  2123,  1005,  1056,  7392,  1012,\n",
              "          2446,  2482, 12088,  2089,  3613,  2000,  2599,  4713, 27891,  1999,\n",
              "          2859,  2023,  2095,  1012, 18817,  1010,  2164, 20075,  1010,  8744,\n",
              "          2012,  2440,  3977,  2197,  2095,  2004,  2537,  3062,  1017,  1003,\n",
              "          1012,  2009,  2064,  2763,  2562,  3269,  8192,  3446,  2152,  2065,\n",
              "          1037,  4171,  3013, 12992,  2015,  2235,  1011,  3194,  2482,  4341,\n",
              "          1010,  2029, 15821,  6146,  1003,  1997,  2049, 24636,  1999,  2859,\n",
              "          1012,  2664,  2130,  1996,  2482,  4435,  2008,  1005,  1055,  2426,\n",
              "          2859,  1005,  1055,  2048,  2087,  6871,  2003,  3497,  2000,  2031,\n",
              "          2205,  2172,  3977,  2044,  2418,  1012, 10793,  4341,  2031,  2042,\n",
              "          3652,  3435,  2438,  2000,  2674,  2049,  3977,  7457,  1012,  2047,\n",
              "         26046,  4886, 16511,  2031,  3271,  4762,  2103, 22517,  6599, 12154,\n",
              "          2664, 10831,  2145,  8840,  5358,  1012, 16878,  5344,  1037,  4389,\n",
              "          4450,  3006,  1010,  2659,  3309,  2282,  6165,  2000,  8744,  6368,\n",
              "          1998,  6599,  5285, 10450, 18605,  2004,  3522,  2103, 22517, 12154,\n",
              "          2031,  2042,  2419,  2011,  1996, 21722,  6903,  1012,  1996,  5257,\n",
              "          1997,  3020,  3037,  6165,  1998, 11103, 18322,  2071,  5245,  2039,\n",
              "         14684, 10322,  1005,  1055, 11103,  5651,  1999,  2418,  1012,  1996,\n",
              "         16021, 27595,  4423,  2049, 10518,  2011,  2471,  2753,  1003,  1999,\n",
              "          2355,  2011,  8744, 14684, 10322, 13058,  1012,  1998, 28043,  1996,\n",
              "          3734, 11103,  1005,  1055,  2709,  2083, 18612,  9031,  1998, 18322,\n",
              "          1012, 13343,  5309,  9529, 24081,  1010, 14684, 10322,  1005,  1055,\n",
              "          1018,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  3445,  4180,  8381,  2006,  4684,  5733,  2089,  2582,  3298,\n",
              "         22495,  2107,  2004,  5830,  1998, 18126,  9224,  2000,  2713,  2058,\n",
              "          1011,  1996,  1011,  2327,  4684,  2678, 14927,  1010,  2096,  9564,\n",
              "          4748, 26178,  2000,  1996,  4274,  1012, 26381,  1998, 13855, 10523,\n",
              "          2584,  3943,  1003,  1997,  2561,  3784,  2678,  3248,  1999,  1996,\n",
              "          2959,  4284,  1010,  2429,  2000,  1051, 18232,  2721,  1010, 19383,\n",
              "          2013,  2459,  1003,  1999,  1018,  4160, 17134,  1012,  1037,  2193,\n",
              "          1997,  4180, 22495,  2031,  5838,  2000,  2023,  9874,  1010,  2007,\n",
              "          2310, 21885,  2239, 13856,  1037,  4684,  2678,  2326,  2000,  2834,\n",
              "          2023,  2621,  1012,  2120,  2660,  2924,  1005,  1055, 16565, 16746,\n",
              "          2097, 11160,  2006,  2019,  7552,  3997,  1997,  2449,  1998,  5971,\n",
              "          8169,  1010,  2029, 10776,  5201,  3515,  1003,  1997,  2049,  1015,\n",
              "          2232,  3653,  2696,  2595,  5618,  1012,  2122,  3197,  3662,  6540,\n",
              "          5658,  3037, 17034,  1010, 16396,  3436,  1037, 11251,  1999,  7325,\n",
              "          8169,  1012,  3006,  3318,  2036,  6753,  2049,  6599,  1010,  2004,\n",
              "          3006,  5285, 10450, 18605, 20145,  5157,  2005,  3891,  2968,  1998,\n",
              "          9837,  2449,  1012,  4359,  4923,  5366,  8945,  3207,  2092,  2005,\n",
              "          2049, 16565,  2205,  1012, 10329,  1010,  6583,  2497,  1998, 12746,\n",
              "          1005,  5618,  2097,  9015,  2013,  1996,  3818,  1020,  1011, 17531,\n",
              "         12767,  2006, 22393, 14680,  1012,  1996,  3112,  1997,  9099, 28621,\n",
              "          2850,  1005,  1055,  1002,  2321,  4551,  4366,  2104,  1996,  2167,\n",
              "          2137,  2489,  3119,  3820, 25484,  2006,  1996,  2194,  4760,  1996,\n",
              "         13117,  1005,  1055, 14920,  2011,  1996,  1057,  1012,  1055,  1012,\n",
              "          4504,  2013, 10662,  1011,  2241,  9147,  1012,  1037,  2093,  1011,\n",
              "          2266,  6583,  6199,  2050,  5997,  2089,  2196,  2131,  1037,  3382,\n",
              "          2000, 10663,  2054,  2052,  2022,  1037,  2086,  1011,  2146, 18010,\n",
              "          2832,  1010,  3391,  2065,  1037,  3951,  4150,  2343,  1998,  2058,\n",
              "         22299,  2015,  1996, 14920,  1012,  2087,  6583,  6199,  2050, 11936,\n",
              "          7392,  2005,  2019,  2779,  1016, 16653,  2006,  1996,  7922,  1012,\n",
              "          3032,  2663,  2087,  1997,  1996,  3588,  8931,  2008,  2123,  1005,\n",
              "          1056,  7392,  1012,  2446,  2482, 12088,  2089,  3613,  2000,  2599,\n",
              "          4713, 27891,  1999,  2859,  2023,  2095,  1012, 18817,  1010,  2164,\n",
              "         20075,  1010,  2743,  2012,  2440,  3977,  2197,  2095,  2004,  2537,\n",
              "          3062,  1017,  1003,  1012,  2009,  2064,  2763,  2562,  3269,  8192,\n",
              "          3446,  2152,  2065,  1037,  4171,  3013, 12992,  2015,  2235,  1011,\n",
              "          3194,  2482,  4341,  1010,  2029, 15821,  6146,  1003,  1997,  2049,\n",
              "         24636,  1999,  2859,  1012,  2664,  2130,  1996,  2482,  4435,  2008,\n",
              "          1005,  1055,  2426,  2859,  1005,  1055,  2048,  2087,  6871,  2003,\n",
              "          3497,  2000,  2031,  2205,  2172,  3977,  2044,  2418,  1012, 10793,\n",
              "          4341,  2031,  2042,  3652,  3435,  2438,  2000,  2674,  2049,  3977,\n",
              "          7457,  1012,  2047, 26046,  4886, 16511,  2031,  3271,  4762,  2103,\n",
              "         22517,  6599, 12154,  2664, 10831,  2145,  8840,  5358,  1012, 16878,\n",
              "          5344,  1037,  4389,  4450,  3006,  1010,  2659,  3309,  2282,  6165,\n",
              "          2000,  9958,  6368,  1998,  6599,  5285, 10450, 18605,  2004,  3522,\n",
              "          2103, 22517, 12154,  2031,  2042,  2419,  2011,  1996, 21722,  6903,\n",
              "          1012,  1996,  5257,  1997,  3020,  3037,  6165,  1998, 11103, 18322,\n",
              "          2071,  5245,  2039, 14684, 10322,  1005,  1055, 11103,  5651,  1999,\n",
              "          2418,  1012,  1996, 16021, 27595,  4423,  2049, 10518,  2011,  2471,\n",
              "          2753,  1003,  1999,  2355,  2011, 13131, 14684, 10322, 13058,  1012,\n",
              "          1998, 28043,  1996,  3734, 11103,  1005,  1055,  2709,  2083, 18612,\n",
              "          9031,  1998, 18322,  1012, 13343,  5309,  9529, 24081,  1010, 14684,\n",
              "         10322,   102]])}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "inputs['labels'] = inputs1.input_ids.detach().clone()\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mask array\n",
        "mask_arr = (inputs.input_ids == 8744) * (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
        "print(mask_arr[0][39:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUIyu4uQIrUf",
        "outputId": "7fef39ae-536d-400e-b424-9d81e6e1334b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
            "        False])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.input_ids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QOCweZckTa4",
        "outputId": "6bb8dff3-d115-4e81-abc3-1ada817552a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbjQkUO6s2M2",
        "outputId": "aaa55187-75d4-4d7f-e933-723bf44d9b68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[39, 134, 268, 319, 428, 482]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# create selection from mask_arr\n",
        "selection = []\n",
        "\n",
        "for i in range(inputs.input_ids.shape[0]):\n",
        "    selection.append(\n",
        "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
        "    )\n",
        "\n",
        "selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xn9stm6s2QP",
        "outputId": "4b218a57-918c-4b2d-b08b-ee8a02d76e1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  3445,  4180,  8381,  2006,  4684,  5733,  2089,  2582,  3298,\n",
              "         22495,  2107,  2004,  5830,  1998, 18126,  9224,  2000,  2713,  2058,\n",
              "          1011,  1996,  1011,  2327,  4684,  2678, 14927,  1010,  2096,  9564,\n",
              "          4748, 26178,  2000,  1996,  4274,  1012, 26381,  1998, 13855,   103,\n",
              "          2584,  3943,  1003,  1997,  2561,  3784,  2678,  3248,  1999,  1996,\n",
              "          2959,  4284,  1010,  2429,  2000,  1051, 18232,  2721,  1010, 19383,\n",
              "          2013,  2459,  1003,  1999,  1018,  4160, 17134,  1012,  1037,  2193,\n",
              "          1997,  4180, 22495,  2031,  5838,  2000,  2023,  9874,  1010,  2007,\n",
              "          2310, 21885,  2239, 13856,  1037,  4684,  2678,  2326,  2000,  2834,\n",
              "          2023,  2621,  1012,  2120,  2660,  2924,  1005,  1055, 16565, 16746,\n",
              "          2097, 11160,  2006,  2019,  7552,  3997,  1997,  2449,  1998,  5971,\n",
              "          8169,  1010,  2029, 10776,  5201,  3515,  1003,  1997,  2049,  1015,\n",
              "          2232,  3653,  2696,  2595,  5618,  1012,  2122,  3197,  3662,  6540,\n",
              "          5658,  3037, 17034,  1010,   103,  1037, 11251,  1999,  7325,  8169,\n",
              "          1012,  3006,  3318,  2036,  6753,  2049,  6599,  1010,  2004,  3006,\n",
              "          5285, 10450, 18605, 20145,  5157,  2005,  3891,  2968,  1998,  9837,\n",
              "          2449,  1012,  4359,  4923,  5366,  8945,  3207,  2092,  2005,  2049,\n",
              "         16565,  2205,  1012, 10329,  1010,  6583,  2497,  1998, 12746,  1005,\n",
              "          5618,  2097,  9015,  2013,  1996,  3818,  1020,  1011, 17531, 12767,\n",
              "          2006, 22393, 14680,  1012,  1996,  3112,  1997,  9099, 28621,  2850,\n",
              "          1005,  1055,  1002,  2321,  4551,  4366,  2104,  1996,  2167,  2137,\n",
              "          2489,  3119,  3820, 25484,  2006,  1996,  2194,  4760,  1996, 13117,\n",
              "          1005,  1055, 14920,  2011,  1996,  1057,  1012,  1055,  1012,  4504,\n",
              "          2013, 10662,  1011,  2241,  9147,  1012,  1037,  2093,  1011,  2266,\n",
              "          6583,  6199,  2050,  5997,  2089,  2196,  2131,  1037,  3382,  2000,\n",
              "         10663,  2054,  2052,  2022,  1037,  2086,  1011,  2146, 18010,  2832,\n",
              "          1010,  3391,  2065,  1037,  3951,  4150,  2343,  1998,   103,  1996,\n",
              "         14920,  1012,  2087,  6583,  6199,  2050, 11936,  7392,  2005,  2019,\n",
              "          2779,  1016, 16653,  2006,  1996,  7922,  1012,  3032,  2663,  2087,\n",
              "          1997,  1996,  3588,  8931,  2008,  2123,  1005,  1056,  7392,  1012,\n",
              "          2446,  2482, 12088,  2089,  3613,  2000,  2599,  4713, 27891,  1999,\n",
              "          2859,  2023,  2095,  1012, 18817,  1010,  2164, 20075,  1010,   103,\n",
              "          2012,  2440,  3977,  2197,  2095,  2004,  2537,  3062,  1017,  1003,\n",
              "          1012,  2009,  2064,  2763,  2562,  3269,  8192,  3446,  2152,  2065,\n",
              "          1037,  4171,  3013, 12992,  2015,  2235,  1011,  3194,  2482,  4341,\n",
              "          1010,  2029, 15821,  6146,  1003,  1997,  2049, 24636,  1999,  2859,\n",
              "          1012,  2664,  2130,  1996,  2482,  4435,  2008,  1005,  1055,  2426,\n",
              "          2859,  1005,  1055,  2048,  2087,  6871,  2003,  3497,  2000,  2031,\n",
              "          2205,  2172,  3977,  2044,  2418,  1012, 10793,  4341,  2031,  2042,\n",
              "          3652,  3435,  2438,  2000,  2674,  2049,  3977,  7457,  1012,  2047,\n",
              "         26046,  4886, 16511,  2031,  3271,  4762,  2103, 22517,  6599, 12154,\n",
              "          2664, 10831,  2145,  8840,  5358,  1012, 16878,  5344,  1037,  4389,\n",
              "          4450,  3006,  1010,  2659,  3309,  2282,  6165,  2000,   103,  6368,\n",
              "          1998,  6599,  5285, 10450, 18605,  2004,  3522,  2103, 22517, 12154,\n",
              "          2031,  2042,  2419,  2011,  1996, 21722,  6903,  1012,  1996,  5257,\n",
              "          1997,  3020,  3037,  6165,  1998, 11103, 18322,  2071,  5245,  2039,\n",
              "         14684, 10322,  1005,  1055, 11103,  5651,  1999,  2418,  1012,  1996,\n",
              "         16021, 27595,  4423,  2049, 10518,  2011,  2471,  2753,  1003,  1999,\n",
              "          2355,  2011,   103, 14684, 10322, 13058,  1012,  1998, 28043,  1996,\n",
              "          3734, 11103,  1005,  1055,  2709,  2083, 18612,  9031,  1998, 18322,\n",
              "          1012, 13343,  5309,  9529, 24081,  1010, 14684, 10322,  1005,  1055,\n",
              "          1018,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# apply selection index to inputs.input_ids, adding MASK tokens\n",
        "\n",
        "for i in range(inputs.input_ids.shape[0]):\n",
        "    inputs.input_ids[i, selection[i]] = 103\n",
        "\n",
        "inputs.input_ids"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MeditationsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "metadata": {
        "id": "eLfmcy2TMh1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MeditationsDataset(inputs)\n"
      ],
      "metadata": {
        "id": "SEa2OYciMh4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "lz4I0BcQMh8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# and move our model over to the selected device\n",
        "model.to(device)\n",
        "# activate training mode\n",
        "model.train()"
      ],
      "metadata": {
        "id": "6-NvPvtRMh-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "# initialize optimizer\n",
        "optim = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "uiCj0uSVNCvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # for our progress bar\n",
        "\n",
        "epochs = 40\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # setup loop with TQDM and dataloader\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch in loop:\n",
        "        # initialize calculated gradients (from prev step)\n",
        "        optim.zero_grad()\n",
        "        # pull all tensor batches required for training\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        # process\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        labels=labels)\n",
        "        # extract loss\n",
        "        loss = outputs.loss\n",
        "        # calculate loss for every parameter that needs grad update\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "        # print relevant info to progress bar\n",
        "        logits = outputs.logits\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjdAW9tfNHjF",
        "outputId": "ab1559dc-e139-448e-f848-5c0c00aab33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n",
            "Epoch 0: 100%|██████████| 1/1 [00:08<00:00,  8.66s/it, loss=13.6]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:09<00:00,  9.43s/it, loss=8.6]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:07<00:00,  7.97s/it, loss=6.04]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:08<00:00,  8.63s/it, loss=6.1]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:09<00:00,  9.57s/it, loss=5.88]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:09<00:00,  9.99s/it, loss=5.52]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:08<00:00,  8.18s/it, loss=5.27]\n",
            "Epoch 7: 100%|██████████| 1/1 [00:07<00:00,  7.88s/it, loss=5.11]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:08<00:00,  8.05s/it, loss=4.84]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:08<00:00,  8.12s/it, loss=4.62]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:08<00:00,  8.31s/it, loss=4.5]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:09<00:00,  9.16s/it, loss=4.25]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:08<00:00,  8.34s/it, loss=4.06]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:08<00:00,  8.48s/it, loss=3.87]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:08<00:00,  8.18s/it, loss=3.68]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it, loss=3.47]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:09<00:00,  9.51s/it, loss=3.28]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:07<00:00,  7.86s/it, loss=3.05]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:08<00:00,  8.07s/it, loss=2.89]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:08<00:00,  8.36s/it, loss=2.67]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:08<00:00,  8.35s/it, loss=2.5]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:07<00:00,  7.94s/it, loss=2.25]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:08<00:00,  8.01s/it, loss=2.14]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:07<00:00,  7.91s/it, loss=1.92]\n",
            "Epoch 24: 100%|██████████| 1/1 [00:08<00:00,  8.24s/it, loss=1.77]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:08<00:00,  8.17s/it, loss=1.57]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:07<00:00,  7.93s/it, loss=1.43]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:07<00:00,  7.98s/it, loss=1.24]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:07<00:00,  7.99s/it, loss=1.09]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:08<00:00,  8.28s/it, loss=0.98]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:08<00:00,  8.53s/it, loss=0.822]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:08<00:00,  8.49s/it, loss=0.763]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:08<00:00,  8.14s/it, loss=0.654]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:08<00:00,  8.04s/it, loss=0.603]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:08<00:00,  8.06s/it, loss=0.518]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:08<00:00,  8.31s/it, loss=0.437]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:08<00:00,  8.56s/it, loss=0.398]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:12<00:00, 12.17s/it, loss=0.342]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:08<00:00,  8.79s/it, loss=0.323]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:08<00:00,  8.60s/it, loss=0.278]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing model"
      ],
      "metadata": {
        "id": "PUesL5Pnytow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S52_L7K4zQGP",
        "outputId": "7b266bbf-7926-40cc-cef5-f1c6927b2057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9b7ff39a-50cc-431b-84a5-cffc4521ea8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>INDEX</th>\n",
              "      <th>QUESTION</th>\n",
              "      <th>ANSWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15000</td>\n",
              "      <td>15000</td>\n",
              "      <td>While construction has begun on the Nord Strea...</td>\n",
              "      <td>grant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15001</td>\n",
              "      <td>15001</td>\n",
              "      <td>A case against 47 people, including OMV execut...</td>\n",
              "      <td>passed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15002</td>\n",
              "      <td>15002</td>\n",
              "      <td>Property insurers are positioning themselves t...</td>\n",
              "      <td>tied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15003</td>\n",
              "      <td>15003</td>\n",
              "      <td>Low-cost European airlines averaged 9% capacit...</td>\n",
              "      <td>garner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15004</td>\n",
              "      <td>15004</td>\n",
              "      <td>Some of the junket operators integral to Macau...</td>\n",
              "      <td>plunged</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>19995</td>\n",
              "      <td>19995</td>\n",
              "      <td>Manufacturing PMIs for new orders, a bellwethe...</td>\n",
              "      <td>dropped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>19996</td>\n",
              "      <td>19996</td>\n",
              "      <td>Approaching the fourth anniversary of Dodd-Fra...</td>\n",
              "      <td>vote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>19997</td>\n",
              "      <td>19997</td>\n",
              "      <td>A 2015 spinoff of Dupont's TiO2 business is on...</td>\n",
              "      <td>fell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>19998</td>\n",
              "      <td>19998</td>\n",
              "      <td>Margins for Texas merchant generators Calpine ...</td>\n",
              "      <td>threatens</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>19999</td>\n",
              "      <td>19999</td>\n",
              "      <td>In addition to flagging relatively higher 6x d...</td>\n",
              "      <td>secured</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b7ff39a-50cc-431b-84a5-cffc4521ea8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b7ff39a-50cc-431b-84a5-cffc4521ea8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b7ff39a-50cc-431b-84a5-cffc4521ea8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0  ...     ANSWER\n",
              "0          15000  ...      grant\n",
              "1          15001  ...     passed\n",
              "2          15002  ...       tied\n",
              "3          15003  ...     garner\n",
              "4          15004  ...    plunged\n",
              "...          ...  ...        ...\n",
              "4995       19995  ...    dropped\n",
              "4996       19996  ...       vote\n",
              "4997       19997  ...       fell\n",
              "4998       19998  ...  threatens\n",
              "4999       19999  ...    secured\n",
              "\n",
              "[5000 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_arr = []\n",
        "for i in range(30):\n",
        "  text = df_test['QUESTION'][i]\n",
        "  split_arr.append(text.split(\"[BLANK]\"))\n",
        "\n",
        "df_T = df_test[:30]\n",
        "df_split = pd.DataFrame(split_arr,columns=['split1','split2'])\n",
        "df_T = pd.concat([df_T,df_split],axis=1)\n",
        "df_T = df_T[['QUESTION','ANSWER','split1','split2']]\n",
        "df_T"
      ],
      "metadata": {
        "id": "Ms8p1GdnRjUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "1bceb24e-3e34-4e6e-db64-fbf68a171f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-702121c8-d7bb-44c0-b05e-3462658c8ed1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QUESTION</th>\n",
              "      <th>ANSWER</th>\n",
              "      <th>split1</th>\n",
              "      <th>split2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>While construction has begun on the Nord Strea...</td>\n",
              "      <td>grant</td>\n",
              "      <td>While construction has begun on the Nord Strea...</td>\n",
              "      <td>the necessary approvals. Nord Stream 2 is als...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A case against 47 people, including OMV execut...</td>\n",
              "      <td>passed</td>\n",
              "      <td>A case against 47 people, including OMV execut...</td>\n",
              "      <td>on to the buyer. Yet, the allegations could a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Property insurers are positioning themselves t...</td>\n",
              "      <td>tied</td>\n",
              "      <td>Property insurers are positioning themselves t...</td>\n",
              "      <td>to an unsustainable system. Modest reforms pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Low-cost European airlines averaged 9% capacit...</td>\n",
              "      <td>garner</td>\n",
              "      <td>Low-cost European airlines averaged 9% capacit...</td>\n",
              "      <td>higher yields. EasyJet added only 2.5%, compa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Some of the junket operators integral to Macau...</td>\n",
              "      <td>plunged</td>\n",
              "      <td>Some of the junket operators integral to Macau...</td>\n",
              "      <td>42% in the first quarter. With close relation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Recovering state budgets are supporting road-r...</td>\n",
              "      <td>led</td>\n",
              "      <td>Recovering state budgets are supporting road-r...</td>\n",
              "      <td>by pavement spending, up 8.5%. Pavement const...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>An increase in the number of U.S. hotel rooms ...</td>\n",
              "      <td>experience</td>\n",
              "      <td>An increase in the number of U.S. hotel rooms ...</td>\n",
              "      <td>this decline first, since expansion there has...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>BlackRock, Prudential Financial and other mort...</td>\n",
              "      <td>narrowing</td>\n",
              "      <td>BlackRock, Prudential Financial and other mort...</td>\n",
              "      <td>the $98 billion lawsuit against the bank in i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Legislation that would give the U.S. Departmen...</td>\n",
              "      <td>controls</td>\n",
              "      <td>Legislation that would give the U.S. Departmen...</td>\n",
              "      <td>either chamber of Congress, this measure favo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Neither side of the legal challenge to the EPA...</td>\n",
              "      <td>committed</td>\n",
              "      <td>Neither side of the legal challenge to the EPA...</td>\n",
              "      <td>to seeing the process through to the end. Law...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Daimler's modest 2017 guidance, restrained by ...</td>\n",
              "      <td>lagged</td>\n",
              "      <td>Daimler's modest 2017 guidance, restrained by ...</td>\n",
              "      <td>the Stoxx auto index in 2016, yet is unlikely...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Goldman Sachs has gained the lead among equity...</td>\n",
              "      <td>ranked</td>\n",
              "      <td>Goldman Sachs has gained the lead among equity...</td>\n",
              "      <td>No. 1 or No. 2 since 2001, lost share and has...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>New regulation, while a key culprit, isn't the...</td>\n",
              "      <td>estimates</td>\n",
              "      <td>New regulation, while a key culprit, isn't the...</td>\n",
              "      <td>25% of demand for new drivers will come from ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>KKR's fundraising increased in 2015-17 followi...</td>\n",
              "      <td>accelerating</td>\n",
              "      <td>KKR's fundraising increased in 2015-17 followi...</td>\n",
              "      <td>deployments, given elevated levels of dry pow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The U.S. Citizenship and Immigration Services ...</td>\n",
              "      <td>accepting</td>\n",
              "      <td>The U.S. Citizenship and Immigration Services ...</td>\n",
              "      <td>applications in May, meaning the winning cont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Agricultural chemical stocks correlate with cr...</td>\n",
              "      <td>depend</td>\n",
              "      <td>Agricultural chemical stocks correlate with cr...</td>\n",
              "      <td>on farmers' incentive to spend on each produc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Food spending makes up more than 40% of Pakist...</td>\n",
              "      <td>trade</td>\n",
              "      <td>Food spending makes up more than 40% of Pakist...</td>\n",
              "      <td>down to cheaper products during periods of hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>A silver lining in the generally weak PJM grid...</td>\n",
              "      <td>suggests</td>\n",
              "      <td>A silver lining in the generally weak PJM grid...</td>\n",
              "      <td>private equity firms, the main plant builders...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Europe's natural gas consumption will remain u...</td>\n",
              "      <td>fall</td>\n",
              "      <td>Europe's natural gas consumption will remain u...</td>\n",
              "      <td>. Rising renewable capacity amid decarbonizati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Yahoo isn't likely to successfully use a U.S. ...</td>\n",
              "      <td>proceed</td>\n",
              "      <td>Yahoo isn't likely to successfully use a U.S. ...</td>\n",
              "      <td>, and under the May ruling, the plaintiff here...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Great Wall Motor's WEY SUV is giving it little...</td>\n",
              "      <td>hit</td>\n",
              "      <td>Great Wall Motor's WEY SUV is giving it little...</td>\n",
              "      <td>showrooms last spring when it was cannibalizi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Gazprom's ability to maintain and expand its d...</td>\n",
              "      <td>become</td>\n",
              "      <td>Gazprom's ability to maintain and expand its d...</td>\n",
              "      <td>a threat. Gazprom Neft's oil and gas output w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Steel Dynamics Inc., is the second-largest dom...</td>\n",
              "      <td>starts</td>\n",
              "      <td>Steel Dynamics Inc., is the second-largest dom...</td>\n",
              "      <td>with steel scrap, which it then melts, using ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Rapidly increasing actual and alternative supp...</td>\n",
              "      <td>consumed</td>\n",
              "      <td>Rapidly increasing actual and alternative supp...</td>\n",
              "      <td>every day. Yet in the aftermath of fears of \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Of all U.S. banks easing commercial and indust...</td>\n",
              "      <td>cited</td>\n",
              "      <td>Of all U.S. banks easing commercial and indust...</td>\n",
              "      <td>by 34% of large and 41% of small banks, down ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Relative spot trucking demand in North America...</td>\n",
              "      <td>attributed</td>\n",
              "      <td>Relative spot trucking demand in North America...</td>\n",
              "      <td>to several factors, including difficult year-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>AbbVie's Venclexta may find a role in treating...</td>\n",
              "      <td>finding</td>\n",
              "      <td>AbbVie's Venclexta may find a role in treating...</td>\n",
              "      <td>an earlier role, given practice-changing data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>MetLife is seeking to extend beyond July 11 a ...</td>\n",
              "      <td>granted</td>\n",
              "      <td>MetLife is seeking to extend beyond July 11 a ...</td>\n",
              "      <td>by the court, an abeyance of the case while t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Dominion received Federal Energy Regulatory Co...</td>\n",
              "      <td>estimated</td>\n",
              "      <td>Dominion received Federal Energy Regulatory Co...</td>\n",
              "      <td>$3.4 billion to $3.8 billion cost and capacit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Amazon.com's entry to Australia could upend th...</td>\n",
              "      <td>shopping</td>\n",
              "      <td>Amazon.com's entry to Australia could upend th...</td>\n",
              "      <td>mall retail sales, limiting landlords' abilit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-702121c8-d7bb-44c0-b05e-3462658c8ed1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-702121c8-d7bb-44c0-b05e-3462658c8ed1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-702121c8-d7bb-44c0-b05e-3462658c8ed1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             QUESTION  ...                                             split2\n",
              "0   While construction has begun on the Nord Strea...  ...   the necessary approvals. Nord Stream 2 is als...\n",
              "1   A case against 47 people, including OMV execut...  ...   on to the buyer. Yet, the allegations could a...\n",
              "2   Property insurers are positioning themselves t...  ...   to an unsustainable system. Modest reforms pr...\n",
              "3   Low-cost European airlines averaged 9% capacit...  ...   higher yields. EasyJet added only 2.5%, compa...\n",
              "4   Some of the junket operators integral to Macau...  ...   42% in the first quarter. With close relation...\n",
              "5   Recovering state budgets are supporting road-r...  ...   by pavement spending, up 8.5%. Pavement const...\n",
              "6   An increase in the number of U.S. hotel rooms ...  ...   this decline first, since expansion there has...\n",
              "7   BlackRock, Prudential Financial and other mort...  ...   the $98 billion lawsuit against the bank in i...\n",
              "8   Legislation that would give the U.S. Departmen...  ...   either chamber of Congress, this measure favo...\n",
              "9   Neither side of the legal challenge to the EPA...  ...   to seeing the process through to the end. Law...\n",
              "10  Daimler's modest 2017 guidance, restrained by ...  ...   the Stoxx auto index in 2016, yet is unlikely...\n",
              "11  Goldman Sachs has gained the lead among equity...  ...   No. 1 or No. 2 since 2001, lost share and has...\n",
              "12  New regulation, while a key culprit, isn't the...  ...   25% of demand for new drivers will come from ...\n",
              "13  KKR's fundraising increased in 2015-17 followi...  ...   deployments, given elevated levels of dry pow...\n",
              "14  The U.S. Citizenship and Immigration Services ...  ...   applications in May, meaning the winning cont...\n",
              "15  Agricultural chemical stocks correlate with cr...  ...   on farmers' incentive to spend on each produc...\n",
              "16  Food spending makes up more than 40% of Pakist...  ...   down to cheaper products during periods of hi...\n",
              "17  A silver lining in the generally weak PJM grid...  ...   private equity firms, the main plant builders...\n",
              "18  Europe's natural gas consumption will remain u...  ...  . Rising renewable capacity amid decarbonizati...\n",
              "19  Yahoo isn't likely to successfully use a U.S. ...  ...  , and under the May ruling, the plaintiff here...\n",
              "20  Great Wall Motor's WEY SUV is giving it little...  ...   showrooms last spring when it was cannibalizi...\n",
              "21  Gazprom's ability to maintain and expand its d...  ...   a threat. Gazprom Neft's oil and gas output w...\n",
              "22  Steel Dynamics Inc., is the second-largest dom...  ...   with steel scrap, which it then melts, using ...\n",
              "23  Rapidly increasing actual and alternative supp...  ...   every day. Yet in the aftermath of fears of \"...\n",
              "24  Of all U.S. banks easing commercial and indust...  ...   by 34% of large and 41% of small banks, down ...\n",
              "25  Relative spot trucking demand in North America...  ...   to several factors, including difficult year-...\n",
              "26  AbbVie's Venclexta may find a role in treating...  ...   an earlier role, given practice-changing data...\n",
              "27  MetLife is seeking to extend beyond July 11 a ...  ...   by the court, an abeyance of the case while t...\n",
              "28  Dominion received Federal Energy Regulatory Co...  ...   $3.4 billion to $3.8 billion cost and capacit...\n",
              "29  Amazon.com's entry to Australia could upend th...  ...   mall retail sales, limiting landlords' abilit...\n",
              "\n",
              "[30 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for i in range(30):\n",
        "  labels_one_sentence = []\n",
        "  text = df_T['split1'][i] + tokenizer.mask_token + df_T['split2'][i]\n",
        "\n",
        "  input = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
        "  mask_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
        "\n",
        "\n",
        "\n",
        "  output = model(**input)\n",
        "  logits = output.logits\n",
        "\n",
        "  softmax = F.softmax(logits, dim = -1)\n",
        "  mask_word = softmax[0, mask_index, :]\n",
        "\n",
        "  top_10 = torch.topk(mask_word, 5, dim = 1)[1][0]\n",
        "  for token in top_10:\n",
        "    word = tokenizer.decode([token])\n",
        "    labels_one_sentence.append(word)\n",
        "\n",
        "  labels.append(labels_one_sentence)"
      ],
      "metadata": {
        "id": "x77a3lglyru4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label = pd.DataFrame(labels)\n"
      ],
      "metadata": {
        "id": "sXlx7HztyryR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_answer = pd.concat([df_T['ANSWER'],df_label],axis=1)\n",
        "df_answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "KWTJ9VC51Gk1",
        "outputId": "f8a54452-40cb-4e03-e248-9e3bbec09840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-697e1bdd-6dcf-4ac3-bc22-bfa34114d653\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ANSWER</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>grant</td>\n",
              "      <td>obtain</td>\n",
              "      <td>submit</td>\n",
              "      <td>get</td>\n",
              "      <td>complete</td>\n",
              "      <td>secure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>passed</td>\n",
              "      <td>passed</td>\n",
              "      <td>passing</td>\n",
              "      <td>pass</td>\n",
              "      <td>passes</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tied</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>subject</td>\n",
              "      <td>exposed</td>\n",
              "      <td>due</td>\n",
              "      <td>susceptible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>garner</td>\n",
              "      <td>deliver</td>\n",
              "      <td>achieve</td>\n",
              "      <td>obtain</td>\n",
              "      <td>offer</td>\n",
              "      <td>get</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plunged</td>\n",
              "      <td>reached</td>\n",
              "      <td>increased</td>\n",
              "      <td>was</td>\n",
              "      <td>grew</td>\n",
              "      <td>rose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>led</td>\n",
              "      <td>followed</td>\n",
              "      <td>led</td>\n",
              "      <td>fueled</td>\n",
              "      <td>driven</td>\n",
              "      <td>helped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>experience</td>\n",
              "      <td>see</td>\n",
              "      <td>face</td>\n",
              "      <td>suffer</td>\n",
              "      <td>trend</td>\n",
              "      <td>have</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>narrowing</td>\n",
              "      <td>ending</td>\n",
              "      <td>filing</td>\n",
              "      <td>dismissing</td>\n",
              "      <td>in</td>\n",
              "      <td>dismissed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>controls</td>\n",
              "      <td>in</td>\n",
              "      <td>of</td>\n",
              "      <td>from</td>\n",
              "      <td>is</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>committed</td>\n",
              "      <td>committed</td>\n",
              "      <td>loyal</td>\n",
              "      <td>leading</td>\n",
              "      <td>accustomed</td>\n",
              "      <td>devoted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lagged</td>\n",
              "      <td>launched</td>\n",
              "      <td>discontinued</td>\n",
              "      <td>acquired</td>\n",
              "      <td>surpassed</td>\n",
              "      <td>led</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ranked</td>\n",
              "      <td>as</td>\n",
              "      <td>ranked</td>\n",
              "      <td>the</td>\n",
              "      <td>its</td>\n",
              "      <td>stake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>estimates</td>\n",
              "      <td>estimates</td>\n",
              "      <td>estimated</td>\n",
              "      <td>estimate</td>\n",
              "      <td>predict</td>\n",
              "      <td>says</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>accelerating</td>\n",
              "      <td>offering</td>\n",
              "      <td>developing</td>\n",
              "      <td>increasing</td>\n",
              "      <td>growing</td>\n",
              "      <td>expanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>accepting</td>\n",
              "      <td>processing</td>\n",
              "      <td>filing</td>\n",
              "      <td>accepting</td>\n",
              "      <td>handling</td>\n",
              "      <td>process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>depend</td>\n",
              "      <td>depend</td>\n",
              "      <td>depends</td>\n",
              "      <td>rely</td>\n",
              "      <td>depended</td>\n",
              "      <td>impact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>trade</td>\n",
              "      <td>slow</td>\n",
              "      <td>move</td>\n",
              "      <td>cash</td>\n",
              "      <td>settle</td>\n",
              "      <td>cut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>suggests</td>\n",
              "      <td>year</td>\n",
              "      <td>month</td>\n",
              "      <td>night</td>\n",
              "      <td>day</td>\n",
              "      <td>may</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>fall</td>\n",
              "      <td>increase</td>\n",
              "      <td>expand</td>\n",
              "      <td>double</td>\n",
              "      <td>continue</td>\n",
              "      <td>triple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>proceed</td>\n",
              "      <td>proceed</td>\n",
              "      <td>continue</td>\n",
              "      <td>commence</td>\n",
              "      <td>cease</td>\n",
              "      <td>arise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>hit</td>\n",
              "      <td>hit</td>\n",
              "      <td>enter</td>\n",
              "      <td>in</td>\n",
              "      <td>reach</td>\n",
              "      <td>entered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>become</td>\n",
              "      <td>pose</td>\n",
              "      <td>be</td>\n",
              "      <td>remain</td>\n",
              "      <td>poses</td>\n",
              "      <td>present</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>starts</td>\n",
              "      <td>works</td>\n",
              "      <td>begins</td>\n",
              "      <td>processes</td>\n",
              "      <td>starts</td>\n",
              "      <td>trades</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>consumed</td>\n",
              "      <td>consumed</td>\n",
              "      <td>exhausted</td>\n",
              "      <td>barrels</td>\n",
              "      <td>used</td>\n",
              "      <td>produced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>cited</td>\n",
              "      <td>reported</td>\n",
              "      <td>expressed</td>\n",
              "      <td>cited</td>\n",
              "      <td>seen</td>\n",
              "      <td>experienced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>attributed</td>\n",
              "      <td>attributed</td>\n",
              "      <td>due</td>\n",
              "      <td>related</td>\n",
              "      <td>traced</td>\n",
              "      <td>linked</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>finding</td>\n",
              "      <td>finding</td>\n",
              "      <td>considering</td>\n",
              "      <td>in</td>\n",
              "      <td>identifying</td>\n",
              "      <td>understanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>granted</td>\n",
              "      <td>granted</td>\n",
              "      <td>denied</td>\n",
              "      <td>refused</td>\n",
              "      <td>rejected</td>\n",
              "      <td>sustained</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>estimated</td>\n",
              "      <td>estimated</td>\n",
              "      <td>projected</td>\n",
              "      <td>combined</td>\n",
              "      <td>proposed</td>\n",
              "      <td>expected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>shopping</td>\n",
              "      <td>the</td>\n",
              "      <td>-</td>\n",
              "      <td>business</td>\n",
              "      <td>its</td>\n",
              "      <td>their</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-697e1bdd-6dcf-4ac3-bc22-bfa34114d653')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-697e1bdd-6dcf-4ac3-bc22-bfa34114d653 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-697e1bdd-6dcf-4ac3-bc22-bfa34114d653');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          ANSWER           0  ...            3              4\n",
              "0          grant      obtain  ...     complete         secure\n",
              "1         passed      passed  ...       passes           left\n",
              "2           tied  vulnerable  ...          due    susceptible\n",
              "3         garner     deliver  ...        offer            get\n",
              "4        plunged     reached  ...         grew           rose\n",
              "5            led    followed  ...       driven         helped\n",
              "6     experience         see  ...        trend           have\n",
              "7      narrowing      ending  ...           in      dismissed\n",
              "8       controls          in  ...           is            and\n",
              "9      committed   committed  ...   accustomed        devoted\n",
              "10        lagged    launched  ...    surpassed            led\n",
              "11        ranked          as  ...          its          stake\n",
              "12     estimates   estimates  ...      predict           says\n",
              "13  accelerating    offering  ...      growing      expanding\n",
              "14     accepting  processing  ...     handling        process\n",
              "15        depend      depend  ...     depended         impact\n",
              "16         trade        slow  ...       settle            cut\n",
              "17      suggests        year  ...          day            may\n",
              "18          fall    increase  ...     continue         triple\n",
              "19       proceed     proceed  ...        cease          arise\n",
              "20           hit         hit  ...        reach        entered\n",
              "21        become        pose  ...        poses        present\n",
              "22        starts       works  ...       starts         trades\n",
              "23      consumed    consumed  ...         used       produced\n",
              "24         cited    reported  ...         seen    experienced\n",
              "25    attributed  attributed  ...       traced         linked\n",
              "26       finding     finding  ...  identifying  understanding\n",
              "27       granted     granted  ...     rejected      sustained\n",
              "28     estimated   estimated  ...     proposed       expected\n",
              "29      shopping         the  ...          its          their\n",
              "\n",
              "[30 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GGl0HwLP1GsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DxyXIrH4yr11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xeIjR-Pdyr6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cv5miSubyr9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U_5H0YaxysBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "83jjQzCVysEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZpirK6YuQ27"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "finetuning_predict_missingWords.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}